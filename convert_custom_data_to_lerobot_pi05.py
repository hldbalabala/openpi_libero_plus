"""
å°†Aloha hdf5æ•°æ®è½¬æ¢ä¸ºLeRobotæ•°æ®é›†v2.0æ ¼å¼çš„è„šæœ¬ã€‚

ä½¿ç”¨ç¤ºä¾‹: python convert_custom_data_to_lerobot_pi05.py --raw-dir ~/Downloads/hdf5_data --repo-id only_fork
"""

import dataclasses  # å¯¼å…¥æ•°æ®ç±»è£…é¥°å™¨ï¼Œç”¨äºåˆ›å»ºä¸å¯å˜çš„æ•°æ®ç»“æ„
from pathlib import Path  # å¯¼å…¥è·¯å¾„å¤„ç†æ¨¡å—ï¼Œæä¾›é¢å‘å¯¹è±¡çš„æ–‡ä»¶ç³»ç»Ÿè·¯å¾„æ“ä½œ
import shutil  # å¯¼å…¥é«˜çº§æ–‡ä»¶æ“ä½œæ¨¡å—ï¼Œç”¨äºæ–‡ä»¶å’Œç›®å½•çš„å¤åˆ¶ã€ç§»åŠ¨ç­‰æ“ä½œ
from typing import Literal  # å¯¼å…¥å­—é¢é‡ç±»å‹æç¤ºï¼Œç”¨äºé™åˆ¶å˜é‡åªèƒ½å–ç‰¹å®šçš„å­—ç¬¦ä¸²å€¼

import h5py  # å¯¼å…¥HDF5æ–‡ä»¶å¤„ç†åº“ï¼Œç”¨äºè¯»å†™HDF5æ ¼å¼çš„æ•°æ®æ–‡ä»¶
from lerobot.common.datasets.lerobot_dataset import HF_LEROBOT_HOME  # å¯¼å…¥LeRobotæ•°æ®é›†çš„ä¸»ç›®å½•è·¯å¾„
print("HF_LEROBOT_HOME: ", HF_LEROBOT_HOME)
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset  # å¯¼å…¥LeRobotæ•°æ®é›†ç±»
# from lerobot.common.datasets.push_dataset_to_hub._download_raw import download_raw  # æ³¨é‡Šæ‰çš„åŸå§‹æ•°æ®ä¸‹è½½å‡½æ•°
import numpy as np  # å¯¼å…¥NumPyæ•°å€¼è®¡ç®—åº“
import torch  # å¯¼å…¥PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import tqdm  # å¯¼å…¥è¿›åº¦æ¡åº“ï¼Œç”¨äºæ˜¾ç¤ºå¤„ç†è¿›åº¦
import tyro  # å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£æåº“
import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—


@dataclasses.dataclass(frozen=True)  # ä½¿ç”¨æ•°æ®ç±»è£…é¥°å™¨åˆ›å»ºä¸å¯å˜çš„æ•°æ®é…ç½®ç±»
class DatasetConfig:  # å®šä¹‰æ•°æ®é›†é…ç½®ç±»
    use_videos: bool = True  # æ˜¯å¦ä½¿ç”¨è§†é¢‘æ¨¡å¼ï¼Œé»˜è®¤ä¸ºTrue
    tolerance_s: float = 0.0001  # æ—¶é—´å®¹å·®ï¼ˆç§’ï¼‰ï¼Œç”¨äºæ—¶é—´åŒæ­¥ï¼Œé»˜è®¤ä¸º0.0001ç§’
    image_writer_processes: int = 10  # å›¾åƒå†™å…¥è¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º10ä¸ªè¿›ç¨‹
    image_writer_threads: int = 5  # å›¾åƒå†™å…¥çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º5ä¸ªçº¿ç¨‹
    video_backend: str | None = None  # è§†é¢‘åç«¯ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸ºNone
    verbose: bool = False  # æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºFalse


DEFAULT_DATASET_CONFIG = DatasetConfig()  # åˆ›å»ºé»˜è®¤çš„æ•°æ®é›†é…ç½®å®ä¾‹


def create_empty_dataset(  # å®šä¹‰åˆ›å»ºç©ºæ•°æ®é›†çš„å‡½æ•°
    repo_id: str,  # ä»“åº“IDï¼Œç”¨äºæ ‡è¯†æ•°æ®é›†
    robot_type: str,  # æœºå™¨äººç±»å‹
    mode: Literal["video", "image"] = "video",  # æ•°æ®æ¨¡å¼ï¼Œè§†é¢‘æˆ–å›¾åƒï¼Œé»˜è®¤ä¸ºè§†é¢‘
    *,  # å¼ºåˆ¶å…³é”®å­—å‚æ•°åˆ†éš”ç¬¦
    has_velocity: bool = False,  # æ˜¯å¦åŒ…å«é€Ÿåº¦æ•°æ®ï¼Œé»˜è®¤ä¸ºFalse
    has_effort: bool = False,  # æ˜¯å¦åŒ…å«åŠ›çŸ©æ•°æ®ï¼Œé»˜è®¤ä¸ºFalse
    dataset_config: DatasetConfig = DEFAULT_DATASET_CONFIG,  # æ•°æ®é›†é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
) -> LeRobotDataset:  # è¿”å›LeRobotæ•°æ®é›†å¯¹è±¡
    motors = [  # å®šä¹‰æœºå™¨äººå…³èŠ‚åç§°åˆ—è¡¨
        "right_waist",  # å³è…°å…³èŠ‚
        "right_shoulder",  # å³è‚©å…³èŠ‚
        "right_elbow",  # å³è‚˜å…³èŠ‚
        "right_forearm_roll",  # å³å‰è‡‚æ»šè½¬å…³èŠ‚
        "right_wrist_angle",  # å³è…•è§’åº¦å…³èŠ‚
        "right_wrist_rotate",  # å³è…•æ—‹è½¬å…³èŠ‚
        "right_gripper",  # å³å¤¹çˆª
        "left_waist",  # å·¦è…°å…³èŠ‚
        "left_shoulder",  # å·¦è‚©å…³èŠ‚
        "left_elbow",  # å·¦è‚˜å…³èŠ‚
        "left_forearm_roll",  # å·¦å‰è‡‚æ»šè½¬å…³èŠ‚
        "left_wrist_angle",  # å·¦è…•è§’åº¦å…³èŠ‚
        "left_wrist_rotate",  # å·¦è…•æ—‹è½¬å…³èŠ‚
        "left_gripper",  # å·¦å¤¹çˆª
    ]
    cameras = [  # å®šä¹‰ç›¸æœºåç§°åˆ—è¡¨
        "cam_high",  # é«˜ä½ç›¸æœº
        # "cam_low",  # ä½ä½ç›¸æœºï¼ˆå·²æ³¨é‡Šï¼‰
        "cam_left_wrist",  # å·¦è…•ç›¸æœº
        "cam_right_wrist",  # å³è…•ç›¸æœº
    ]

    features = {  # å®šä¹‰æ•°æ®é›†ç‰¹å¾å­—å…¸
        "observation.state": {  # è§‚å¯ŸçŠ¶æ€ç‰¹å¾
            "dtype": "float32",  # æ•°æ®ç±»å‹ä¸º32ä½æµ®ç‚¹æ•°
            "shape": (len(motors),),  # å½¢çŠ¶ä¸ºå…³èŠ‚æ•°é‡çš„ä¸€ç»´æ•°ç»„
            "names": [  # ç‰¹å¾åç§°åˆ—è¡¨
                motors,  # ä½¿ç”¨å…³èŠ‚åç§°åˆ—è¡¨
            ],
        },
        "action": {  # åŠ¨ä½œç‰¹å¾
            "dtype": "float32",  # æ•°æ®ç±»å‹ä¸º32ä½æµ®ç‚¹æ•°
            "shape": (len(motors),),  # å½¢çŠ¶ä¸ºå…³èŠ‚æ•°é‡çš„ä¸€ç»´æ•°ç»„
            "names": [  # ç‰¹å¾åç§°åˆ—è¡¨
                motors,  # ä½¿ç”¨å…³èŠ‚åç§°åˆ—è¡¨
            ],
        },
    }

    if has_velocity:  # å¦‚æœåŒ…å«é€Ÿåº¦æ•°æ®
        features["observation.velocity"] = {  # æ·»åŠ é€Ÿåº¦è§‚å¯Ÿç‰¹å¾
            "dtype": "float32",  # æ•°æ®ç±»å‹ä¸º32ä½æµ®ç‚¹æ•°
            "shape": (len(motors),),  # å½¢çŠ¶ä¸ºå…³èŠ‚æ•°é‡çš„ä¸€ç»´æ•°ç»„
            "names": [  # ç‰¹å¾åç§°åˆ—è¡¨
                motors,  # ä½¿ç”¨å…³èŠ‚åç§°åˆ—è¡¨
            ],
        }

    if has_effort:  # å¦‚æœåŒ…å«åŠ›çŸ©æ•°æ®
        features["observation.effort"] = {  # æ·»åŠ åŠ›çŸ©è§‚å¯Ÿç‰¹å¾
            "dtype": "float32",  # æ•°æ®ç±»å‹ä¸º32ä½æµ®ç‚¹æ•°
            "shape": (len(motors),),  # å½¢çŠ¶ä¸ºå…³èŠ‚æ•°é‡çš„ä¸€ç»´æ•°ç»„
            "names": [  # ç‰¹å¾åç§°åˆ—è¡¨
                motors,  # ä½¿ç”¨å…³èŠ‚åç§°åˆ—è¡¨
            ],
        }

    for cam in cameras:  # éå†æ‰€æœ‰ç›¸æœº
        features[f"observation.images.{cam}"] = {  # ä¸ºæ¯ä¸ªç›¸æœºæ·»åŠ å›¾åƒè§‚å¯Ÿç‰¹å¾
            "dtype": mode,  # æ•°æ®ç±»å‹ä¸ºæŒ‡å®šçš„æ¨¡å¼ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
            "shape": (3, 480, 640),  # å›¾åƒå½¢çŠ¶ï¼š3ä¸ªé€šé“ï¼Œ480åƒç´ é«˜ï¼Œ640åƒç´ å®½
            "names": [  # ç‰¹å¾åç§°åˆ—è¡¨
                "channels",  # é€šé“ç»´åº¦
                "height",  # é«˜åº¦ç»´åº¦
                "width",  # å®½åº¦ç»´åº¦
            ],
        }

    if Path(HF_LEROBOT_HOME / repo_id).exists():  # å¦‚æœæ•°æ®é›†ç›®å½•å·²å­˜åœ¨
        shutil.rmtree(HF_LEROBOT_HOME / repo_id)  # åˆ é™¤ç°æœ‰ç›®å½•

    return LeRobotDataset.create(  # åˆ›å»ºå¹¶è¿”å›LeRobotæ•°æ®é›†
        repo_id=repo_id,  # ä»“åº“ID
        fps=50,  # å¸§ç‡è®¾ç½®ä¸º50fps
        robot_type=robot_type,  # æœºå™¨äººç±»å‹
        features=features,  # ç‰¹å¾å®šä¹‰
        use_videos=dataset_config.use_videos,  # æ˜¯å¦ä½¿ç”¨è§†é¢‘æ¨¡å¼
        tolerance_s=dataset_config.tolerance_s,  # æ—¶é—´å®¹å·®
        image_writer_processes=dataset_config.image_writer_processes,  # å›¾åƒå†™å…¥è¿›ç¨‹æ•°
        image_writer_threads=dataset_config.image_writer_threads,  # å›¾åƒå†™å…¥çº¿ç¨‹æ•°
        video_backend=dataset_config.video_backend,  # è§†é¢‘åç«¯
    )


def get_cameras(hdf5_files: list[Path]) -> list[str]:  # å®šä¹‰è·å–ç›¸æœºåˆ—è¡¨çš„å‡½æ•°
    with h5py.File(hdf5_files[0], "r") as ep:  # æ‰“å¼€ç¬¬ä¸€ä¸ªHDF5æ–‡ä»¶è¿›è¡Œè¯»å–
        # æ–°æ ¼å¼ï¼šä» /camera/color/ è·å–ç›¸æœºåˆ—è¡¨
        if "/camera/color" in ep:  # å¦‚æœå­˜åœ¨æ–°çš„ç›¸æœºç»“æ„
            return [key for key in ep["/camera/color"].keys() if "depth" not in key]  # è¿”å›ä¸åŒ…å«"depth"çš„å›¾åƒé”®åˆ—è¡¨
        else:  # å…¼å®¹æ—§æ ¼å¼
            return [key for key in ep["/observations/images"].keys() if "depth" not in key]  # è¿”å›ä¸åŒ…å«"depth"çš„å›¾åƒé”®åˆ—è¡¨


def has_velocity(hdf5_files: list[Path]) -> bool:  # å®šä¹‰æ£€æŸ¥æ˜¯å¦åŒ…å«é€Ÿåº¦æ•°æ®çš„å‡½æ•°
    with h5py.File(hdf5_files[0], "r") as ep:  # æ‰“å¼€ç¬¬ä¸€ä¸ªHDF5æ–‡ä»¶è¿›è¡Œè¯»å–
        # æ–°æ ¼å¼ï¼šæ£€æŸ¥ /arm/jointStateVelocity/ æ˜¯å¦å­˜åœ¨
        if "/arm/jointStateVelocity" in ep:  # å¦‚æœå­˜åœ¨æ–°çš„é€Ÿåº¦ç»“æ„
            return True  # è¿”å›True
        else:  # å…¼å®¹æ—§æ ¼å¼
            return "/observations/qvel" in ep  # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é€Ÿåº¦è§‚å¯Ÿæ•°æ®


def has_effort(hdf5_files: list[Path]) -> bool:  # å®šä¹‰æ£€æŸ¥æ˜¯å¦åŒ…å«åŠ›çŸ©æ•°æ®çš„å‡½æ•°
    with h5py.File(hdf5_files[0], "r") as ep:  # æ‰“å¼€ç¬¬ä¸€ä¸ªHDF5æ–‡ä»¶è¿›è¡Œè¯»å–
        # æ–°æ ¼å¼ï¼šæ£€æŸ¥ /arm/jointStateEffort/ æ˜¯å¦å­˜åœ¨
        if "/arm/jointStateEffort" in ep:  # å¦‚æœå­˜åœ¨æ–°çš„åŠ›çŸ©ç»“æ„
            return True  # è¿”å›True
        else:  # å…¼å®¹æ—§æ ¼å¼
            return "/observations/effort" in ep  # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŠ›çŸ©è§‚å¯Ÿæ•°æ®


def load_raw_images_per_camera(ep: h5py.File, cameras: list[str], verbose: bool = False) -> dict[str, np.ndarray]:  # å®šä¹‰æŒ‰ç›¸æœºåŠ è½½åŸå§‹å›¾åƒçš„å‡½æ•°
    imgs_per_cam = {}  # åˆå§‹åŒ–æ¯ä¸ªç›¸æœºçš„å›¾åƒå­—å…¸
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼
    is_new_format = "/camera/color" in ep  # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ–°çš„ç›¸æœºç»“æ„
    if verbose:
        print(f"ğŸ” æ£€æµ‹åˆ°æ ¼å¼: {'æ–°æ ¼å¼' if is_new_format else 'æ—§æ ¼å¼'}")
    
    for camera_key in cameras:  # éå†æ‰€æœ‰ç›¸æœº
        if verbose:
            print(f"\nğŸ“· å¤„ç†ç›¸æœº: {camera_key}")
        
        if is_new_format:  # å¦‚æœæ˜¯æ–°æ ¼å¼
            # æ–°æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ç›¸æœºåç§°æ˜ å°„
            camera_mapping = {
                'cam_high': 'front',  # é«˜ä½ç›¸æœºå¯¹åº”front
                'cam_left_wrist': 'left',  # å·¦è…•ç›¸æœºå¯¹åº”left
                'cam_right_wrist': 'right',  # å³è…•ç›¸æœºå¯¹åº”right
            }
            camera = camera_mapping.get(camera_key, camera_key)  # è·å–æ˜ å°„åçš„ç›¸æœºåç§°
            camera_path = f"/camera/color/{camera}"  # æ„å»ºæ–°æ ¼å¼çš„ç›¸æœºè·¯å¾„
        else:  # å…¼å®¹æ—§æ ¼å¼
            if camera_key == 'cam_high':  # å¦‚æœæ˜¯é«˜ä½ç›¸æœº
                camera = 'camera_front'  # æ˜ å°„ä¸ºå‰ç½®ç›¸æœº
            elif camera_key == 'cam_left_wrist':  # å¦‚æœæ˜¯å·¦è…•ç›¸æœº
                camera = 'camera_left'  # æ˜ å°„ä¸ºå·¦ç›¸æœº
            elif camera_key == 'cam_right_wrist':  # å¦‚æœæ˜¯å³è…•ç›¸æœº
                camera = 'camera_right'  # æ˜ å°„ä¸ºå³ç›¸æœº
            camera_path = f"/observations/rgb_images/{camera}"  # æ„å»ºæ—§æ ¼å¼çš„ç›¸æœºè·¯å¾„
        
        if verbose:
            print(f"  ğŸ“‚ ç›¸æœºè·¯å¾„: {camera_path}")
        
        if camera_path not in ep:  # å¦‚æœç›¸æœºè·¯å¾„ä¸å­˜åœ¨
            if verbose:
                print(f"  âŒ è­¦å‘Š: ç›¸æœºè·¯å¾„ä¸å­˜åœ¨ {camera_path}")
                # åˆ—å‡ºå¯ç”¨çš„ç›¸æœºè·¯å¾„
                if is_new_format and "/camera/color" in ep:
                    available_cameras = list(ep["/camera/color"].keys())
                    print(f"  ğŸ“‹ å¯ç”¨çš„ç›¸æœº: {available_cameras}")
                elif not is_new_format and "/observations/images" in ep:
                    available_cameras = list(ep["/observations/images"].keys())
                    print(f"  ğŸ“‹ å¯ç”¨çš„ç›¸æœº: {available_cameras}")
            continue  # è·³è¿‡è¿™ä¸ªç›¸æœº
        
        # æ£€æŸ¥æ•°æ®å½¢çŠ¶å’Œç±»å‹
        dataset = ep[camera_path]
        if verbose:
            print(f"  ğŸ“Š æ•°æ®å½¢çŠ¶: {dataset.shape}")
            print(f"  ğŸ·ï¸ æ•°æ®ç±»å‹: {dataset.dtype}")
            print(f"  ğŸ’¾ æ•°æ®å¤§å°: {dataset.size * dataset.dtype.itemsize / 1024 / 1024:.2f} MB")
        
        uncompressed = dataset.ndim == 4  # æ£€æŸ¥å›¾åƒæ˜¯å¦ä¸ºæœªå‹ç¼©æ ¼å¼ï¼ˆ4ç»´ï¼‰
        if verbose:
            print(f"  ğŸ”„ å‹ç¼©çŠ¶æ€: {'æœªå‹ç¼©' if uncompressed else 'å‹ç¼©'}")

        if uncompressed:  # å¦‚æœæ˜¯æœªå‹ç¼©å›¾åƒ
            if verbose:
                print(f"  âœ… åŠ è½½æœªå‹ç¼©å›¾åƒ: {camera_path}")
            # load all images in RAM  # å°†æ‰€æœ‰å›¾åƒåŠ è½½åˆ°å†…å­˜ä¸­
            imgs_array = dataset[:]  # ç›´æ¥è¯»å–æ‰€æœ‰å›¾åƒæ•°æ®
            if verbose:
                print(f"  ğŸ“ˆ åŠ è½½åå½¢çŠ¶: {imgs_array.shape}")
                print(f"  ğŸ¨ å›¾åƒèŒƒå›´: [{imgs_array.min()}, {imgs_array.max()}]")
        else:  # å¦‚æœæ˜¯å‹ç¼©å›¾åƒ
            if verbose:
                print(f"  âœ… åŠ è½½å‹ç¼©å›¾åƒ: {camera_path}")
            import cv2  # å¯¼å…¥OpenCVåº“

            # load one compressed image after the other in RAM and uncompress  # é€ä¸ªåŠ è½½å‹ç¼©å›¾åƒåˆ°å†…å­˜å¹¶è§£å‹ç¼©
            imgs_array = []  # åˆå§‹åŒ–å›¾åƒæ•°ç»„åˆ—è¡¨
            if verbose:
                print(f"  ğŸ”„ å¼€å§‹è§£å‹ç¼© {len(dataset)} å¼ å›¾åƒ...")
            for i, data in enumerate(dataset):  # éå†å‹ç¼©å›¾åƒæ•°æ®
                if verbose and i % 50 == 0:  # æ¯50å¼ å›¾åƒæ‰“å°ä¸€æ¬¡è¿›åº¦
                    print(f"    å¤„ç†è¿›åº¦: {i}/{len(dataset)}")
                # imgs_array.append(cv2.cvtColor(cv2.imdecode(data, 1), cv2.COLOR_BGR2RGB))  # æ³¨é‡Šæ‰çš„BGRåˆ°RGBè½¬æ¢
                decoded_img = cv2.imdecode(np.frombuffer(data, np.uint8), 1)  # è§£ç å‹ç¼©å›¾åƒæ•°æ®
                if decoded_img is not None:
                    imgs_array.append(decoded_img)  # æ·»åŠ åˆ°åˆ—è¡¨
                else:
                    if verbose:
                        print(f"    âš ï¸ è­¦å‘Š: ç¬¬{i}å¼ å›¾åƒè§£ç å¤±è´¥")
            imgs_array = np.array(imgs_array)  # å°†åˆ—è¡¨è½¬æ¢ä¸ºNumPyæ•°ç»„
            if verbose:
                print(f"  ğŸ“ˆ è§£å‹ç¼©åå½¢çŠ¶: {imgs_array.shape}")
                print(f"  ğŸ¨ å›¾åƒèŒƒå›´: [{imgs_array.min()}, {imgs_array.max()}]")

        imgs_per_cam[camera_key] = imgs_array  # å°†å›¾åƒæ•°ç»„å­˜å‚¨åˆ°å¯¹åº”ç›¸æœºé”®ä¸‹
        if verbose:
            print(f"  âœ… æˆåŠŸåŠ è½½ {len(imgs_array)} å¼ å›¾åƒåˆ° {camera_key}")
    
    if verbose:
        print(f"\nğŸ“Š å›¾åƒåŠ è½½æ€»ç»“:")
        for cam_key, img_array in imgs_per_cam.items():
            print(f"  {cam_key}: {img_array.shape} ({img_array.size * img_array.dtype.itemsize / 1024 / 1024:.2f} MB)")
    
    return imgs_per_cam  # è¿”å›æ¯ä¸ªç›¸æœºçš„å›¾åƒå­—å…¸


def calculate_quantiles(hdf5_files: list[Path], verbose: bool = False) -> dict:  # å®šä¹‰è®¡ç®—åˆ†ä½æ•°çš„å‡½æ•°
    """è®¡ç®—æ‰€æœ‰HDF5æ–‡ä»¶ä¸­ç¬¬7å’Œ14ç»´çš„q01å’Œq99åˆ†ä½æ•°"""
    if verbose:
        print("ğŸ”¢ å¼€å§‹è®¡ç®—æ•°æ®åˆ†ä½æ•°...")
    
    all_master_data = []  # å­˜å‚¨æ‰€æœ‰ä¸»æ§ç«¯æ•°æ®
    all_puppet_data = []  # å­˜å‚¨æ‰€æœ‰ä»æ§ç«¯æ•°æ®
    
    for hdf5_file in hdf5_files:  # éå†æ‰€æœ‰HDF5æ–‡ä»¶
        if verbose:
            print(f"  ğŸ“ å¤„ç†æ–‡ä»¶: {hdf5_file.name}")
        
        try:
            with h5py.File(hdf5_file, "r") as ep:  # æ‰“å¼€HDF5æ–‡ä»¶
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼
                is_new_format = "/arm/jointStatePosition" in ep
                
                if is_new_format:  # å¦‚æœæ˜¯æ–°æ ¼å¼
                    # æ–°æ ¼å¼ï¼šä» /arm/jointStatePosition/ è¯»å–å…³èŠ‚ä½ç½®æ•°æ®
                    master_left = ep["/arm/jointStatePosition/masterLeft"][:]  # è¯»å–å·¦è‡‚ä¸»æ§å…³èŠ‚ä½ç½®æ•°æ®
                    master_right = ep["/arm/jointStatePosition/masterRight"][:]  # è¯»å–å³è‡‚ä¸»æ§å…³èŠ‚ä½ç½®æ•°æ®
                    puppet_left = ep["/arm/jointStatePosition/puppetLeft"][:]  # è¯»å–å·¦è‡‚å…³èŠ‚ä½ç½®æ•°æ®
                    puppet_right = ep["/arm/jointStatePosition/puppetRight"][:]  # è¯»å–å³è‡‚å…³èŠ‚ä½ç½®æ•°æ®
                    
                    # åˆå¹¶å·¦å³è‡‚æ•°æ® [right_arm, left_arm]
                    master_data = np.concatenate([master_right, master_left], axis=1)  # åˆå¹¶ä¸»æ§ç«¯æ•°æ®
                    puppet_data = np.concatenate([puppet_right, puppet_left], axis=1)  # åˆå¹¶ä»æ§ç«¯æ•°æ®
                else:  # å…¼å®¹æ—§æ ¼å¼
                    # æ—§æ ¼å¼ï¼šä» /puppet/arm_joint_position å’Œ /master/arm_joint_position è¯»å–æ•°æ®
                    master_data = ep["/master/arm_joint_position"][:]  # è¯»å–ä¸»æ§ç«¯å…³èŠ‚ä½ç½®æ•°æ®
                    puppet_data = ep["/puppet/arm_joint_position"][:]  # è¯»å–ä»æ§ç«¯å…³èŠ‚ä½ç½®æ•°æ®
                
                all_master_data.append(master_data)  # æ·»åŠ åˆ°ä¸»æ§ç«¯æ•°æ®åˆ—è¡¨
                all_puppet_data.append(puppet_data)  # æ·»åŠ åˆ°ä»æ§ç«¯æ•°æ®åˆ—è¡¨
                
                if verbose:
                    print(f"    âœ… åŠ è½½æ•°æ®: master {master_data.shape}, puppet {puppet_data.shape}")
                    
        except Exception as e:
            if verbose:
                print(f"    âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
            continue  # è·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶
    
    if not all_master_data or not all_puppet_data:  # å¦‚æœæ²¡æœ‰æ•°æ®
        if verbose:
            print("  âš ï¸ è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤åˆ†ä½æ•°")
        # è¿”å›é»˜è®¤åˆ†ä½æ•°
        return {
            "master": {
                "q01": [-0.00091, -0.00098],
                "q99": [0.05964, 0.04851]
            },
            "puppet": {
                "q01": [-0.0009800000116229057, -0.0008399999933317304],
                "q99": [0.05914999917149544, 0.047529999166727066]
            }
        }
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    all_master_data = np.concatenate(all_master_data, axis=0)  # åˆå¹¶æ‰€æœ‰ä¸»æ§ç«¯æ•°æ®
    all_puppet_data = np.concatenate(all_puppet_data, axis=0)  # åˆå¹¶æ‰€æœ‰ä»æ§ç«¯æ•°æ®
    
    if verbose:
        print(f"  ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"    master: {all_master_data.shape}")
        print(f"    puppet: {all_puppet_data.shape}")
    
    # è®¡ç®—åˆ†ä½æ•°
    quantiles = {
        "master": {
            "q01": [
                np.percentile(all_master_data[:, 6], 1),   # ç¬¬7ç»´çš„1%åˆ†ä½æ•°
                np.percentile(all_master_data[:, 13], 1)   # ç¬¬14ç»´çš„1%åˆ†ä½æ•°
            ],
            "q99": [
                np.percentile(all_master_data[:, 6], 99),  # ç¬¬7ç»´çš„99%åˆ†ä½æ•°
                np.percentile(all_master_data[:, 13], 99)  # ç¬¬14ç»´çš„99%åˆ†ä½æ•°
            ]
        },
        "puppet": {
            "q01": [
                np.percentile(all_puppet_data[:, 6], 1),   # ç¬¬7ç»´çš„1%åˆ†ä½æ•°
                np.percentile(all_puppet_data[:, 13], 1)   # ç¬¬14ç»´çš„1%åˆ†ä½æ•°
            ],
            "q99": [
                np.percentile(all_puppet_data[:, 6], 99),  # ç¬¬7ç»´çš„99%åˆ†ä½æ•°
                np.percentile(all_puppet_data[:, 13], 99)  # ç¬¬14ç»´çš„99%åˆ†ä½æ•°
            ]
        }
    }
    
    if verbose:
        print(f"  ğŸ“ˆ è®¡ç®—å®Œæˆçš„åˆ†ä½æ•°:")
        print(f"    master q01: {quantiles['master']['q01']}")
        print(f"    master q99: {quantiles['master']['q99']}")
        print(f"    puppet q01: {quantiles['puppet']['q01']}")
        print(f"    puppet q99: {quantiles['puppet']['q99']}")
    
    return quantiles  # è¿”å›è®¡ç®—çš„åˆ†ä½æ•°


def load_raw_episode_data(  # å®šä¹‰åŠ è½½åŸå§‹å‰§é›†æ•°æ®çš„å‡½æ•°
    ep_path: Path,  # å‰§é›†æ–‡ä»¶è·¯å¾„
    quantiles: dict | None = None,  # åˆ†ä½æ•°å­—å…¸ï¼Œç”¨äºæ•°æ®å½’ä¸€åŒ–
    verbose: bool = False,  # æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
) -> tuple[dict[str, np.ndarray], torch.Tensor, torch.Tensor, torch.Tensor | None, torch.Tensor | None]:  # è¿”å›å›¾åƒå­—å…¸ã€çŠ¶æ€ã€åŠ¨ä½œã€é€Ÿåº¦ã€åŠ›çŸ©çš„å…ƒç»„
    with h5py.File(ep_path, "r") as ep:  # æ‰“å¼€HDF5æ–‡ä»¶è¿›è¡Œè¯»å–
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼
        is_new_format = "/arm/jointStatePosition" in ep  # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ–°çš„å…³èŠ‚ä½ç½®ç»“æ„
        
        if is_new_format:  # å¦‚æœæ˜¯æ–°æ ¼å¼
            # æ–°æ ¼å¼ï¼šä» /arm/jointStatePosition/ è¯»å–å…³èŠ‚ä½ç½®æ•°æ®
            puppet_left = ep["/arm/jointStatePosition/puppetLeft"][:]  # è¯»å–å·¦è‡‚å…³èŠ‚ä½ç½®æ•°æ®
            puppet_right = ep["/arm/jointStatePosition/puppetRight"][:]  # è¯»å–å³è‡‚å…³èŠ‚ä½ç½®æ•°æ®
            master_left = ep["/arm/jointStatePosition/masterLeft"][:]  # è¯»å–å·¦è‡‚ä¸»æ§å…³èŠ‚ä½ç½®æ•°æ®
            master_right = ep["/arm/jointStatePosition/masterRight"][:]  # è¯»å–å³è‡‚ä¸»æ§å…³èŠ‚ä½ç½®æ•°æ®
            
            # åˆå¹¶å·¦å³è‡‚æ•°æ® [right_arm, left_arm]
            state = np.concatenate([puppet_right, puppet_left], axis=1)  # åˆå¹¶ä»æ§ç«¯æ•°æ®
            action = np.concatenate([master_right, master_left], axis=1)  # åˆå¹¶ä¸»æ§ç«¯æ•°æ®
            
            if verbose:
                print(f"æ–°æ ¼å¼ - çŠ¶æ€æ•°æ®å½¢çŠ¶: {state.shape}")  # æ‰“å°çŠ¶æ€æ•°æ®å½¢çŠ¶
                print(f"æ–°æ ¼å¼ - åŠ¨ä½œæ•°æ®å½¢çŠ¶: {action.shape}")  # æ‰“å°åŠ¨ä½œæ•°æ®å½¢çŠ¶
        else:  # å…¼å®¹æ—§æ ¼å¼
            # æ—§æ ¼å¼ï¼šä» /puppet/arm_joint_position å’Œ /master/arm_joint_position è¯»å–æ•°æ®
            state = ep["/puppet/arm_joint_position"][:]  # è¯»å–ä»æ§ç«¯å…³èŠ‚ä½ç½®æ•°æ®
            action = ep["/master/arm_joint_position"][:]  # è¯»å–ä¸»æ§ç«¯å…³èŠ‚ä½ç½®æ•°æ®
            if verbose:
                print(f"æ—§æ ¼å¼ - çŠ¶æ€æ•°æ®å½¢çŠ¶: {state.shape}")  # æ‰“å°çŠ¶æ€æ•°æ®å½¢çŠ¶
                print(f"æ—§æ ¼å¼ - åŠ¨ä½œæ•°æ®å½¢çŠ¶: {action.shape}")  # æ‰“å°åŠ¨ä½œæ•°æ®å½¢çŠ¶

        # å½’ä¸€åŒ–ç¬¬7å’Œç¬¬14ç»´å¹¶è£å‰ªåˆ°[0,1]
        if quantiles is not None:  # å¦‚æœåˆ†ä½æ•°æ•°æ®ä¸ä¸ºç©º
            if verbose:
                print(f"  ğŸ”¢ ä½¿ç”¨è®¡ç®—çš„åˆ†ä½æ•°è¿›è¡Œå½’ä¸€åŒ–:")
                print(f"    puppet q01: {quantiles['puppet']['q01']}, q99: {quantiles['puppet']['q99']}")
                print(f"    master q01: {quantiles['master']['q01']}, q99: {quantiles['master']['q99']}")

            # puppetï¼ˆstateï¼‰ç¬¬7ç»´å’Œç¬¬14ç»´
            denom_puppet_7 = (quantiles["puppet"]["q99"][0] - quantiles["puppet"]["q01"][0]) or 1e-9
            denom_puppet_14 = (quantiles["puppet"]["q99"][1] - quantiles["puppet"]["q01"][1]) or 1e-9
            state[:, 6] = np.clip(
                (state[:, 6] - quantiles["puppet"]["q01"][0]) / denom_puppet_7,
                0.0,
                1.0,
            )
            state[:, 13] = np.clip(
                (state[:, 13] - quantiles["puppet"]["q01"][1]) / denom_puppet_14,
                0.0,
                1.0,
            )

            # masterï¼ˆactionï¼‰ç¬¬7ç»´å’Œç¬¬14ç»´
            denom_master_7 = (quantiles["master"]["q99"][0] - quantiles["master"]["q01"][0]) or 1e-9
            denom_master_14 = (quantiles["master"]["q99"][1] - quantiles["master"]["q01"][1]) or 1e-9
            action[:, 6] = np.clip(
                (action[:, 6] - quantiles["master"]["q01"][0]) / denom_master_7,
                0.0,
                1.0,
            )
            action[:, 13] = np.clip(
                (action[:, 13] - quantiles["master"]["q01"][1]) / denom_master_14,
                0.0,
                1.0,
            )
        else:
            if verbose:
                print("  âš ï¸ è­¦å‘Š: æ²¡æœ‰æä¾›åˆ†ä½æ•°æ•°æ®ï¼Œè·³è¿‡å½’ä¸€åŒ–")

        state = torch.from_numpy(state).to(torch.float32)  # å°†çŠ¶æ€æ•°æ®è½¬æ¢ä¸ºPyTorchå¼ é‡
        action = torch.from_numpy(action).to(torch.float32)  # å°†åŠ¨ä½œæ•°æ®è½¬æ¢ä¸ºPyTorchå¼ é‡

        # å¤„ç†é€Ÿåº¦æ•°æ®
        velocity = None  # åˆå§‹åŒ–é€Ÿåº¦æ•°æ®ä¸ºNone
        if is_new_format:  # å¦‚æœæ˜¯æ–°æ ¼å¼
            if "/arm/jointStateVelocity" in ep:  # å¦‚æœå­˜åœ¨æ–°çš„é€Ÿåº¦ç»“æ„
                vel_left = ep["/arm/jointStateVelocity/puppetLeft"][:]  # è¯»å–å·¦è‡‚é€Ÿåº¦æ•°æ®
                vel_right = ep["/arm/jointStateVelocity/puppetRight"][:]  # è¯»å–å³è‡‚é€Ÿåº¦æ•°æ®
                velocity = np.concatenate([vel_right, vel_left], axis=1)  # åˆå¹¶é€Ÿåº¦æ•°æ®
                velocity = torch.from_numpy(velocity).to(torch.float32)  # è½¬æ¢ä¸ºå¼ é‡
        else:  # å…¼å®¹æ—§æ ¼å¼
            if "/observations/qvel" in ep:  # å¦‚æœå­˜åœ¨é€Ÿåº¦è§‚å¯Ÿæ•°æ®
                velocity = torch.from_numpy(ep["/observations/qvel"][:])  # è¯»å–é€Ÿåº¦æ•°æ®å¹¶è½¬æ¢ä¸ºå¼ é‡

        # å¤„ç†åŠ›çŸ©æ•°æ®
        effort = None  # åˆå§‹åŒ–åŠ›çŸ©æ•°æ®ä¸ºNone
        if is_new_format:  # å¦‚æœæ˜¯æ–°æ ¼å¼
            if "/arm/jointStateEffort" in ep:  # å¦‚æœå­˜åœ¨æ–°çš„åŠ›çŸ©ç»“æ„
                effort_left = ep["/arm/jointStateEffort/puppetLeft"][:]  # è¯»å–å·¦è‡‚åŠ›çŸ©æ•°æ®
                effort_right = ep["/arm/jointStateEffort/puppetRight"][:]  # è¯»å–å³è‡‚åŠ›çŸ©æ•°æ®
                effort = np.concatenate([effort_right, effort_left], axis=1)  # åˆå¹¶åŠ›çŸ©æ•°æ®
                effort = torch.from_numpy(effort).to(torch.float32)  # è½¬æ¢ä¸ºå¼ é‡
        else:  # å…¼å®¹æ—§æ ¼å¼
            if "/observations/effort" in ep:  # å¦‚æœå­˜åœ¨åŠ›çŸ©è§‚å¯Ÿæ•°æ®
                effort = torch.from_numpy(ep["/observations/effort"][:])  # è¯»å–åŠ›çŸ©æ•°æ®å¹¶è½¬æ¢ä¸ºå¼ é‡

        imgs_per_cam = load_raw_images_per_camera(  # åŠ è½½æ¯ä¸ªç›¸æœºçš„åŸå§‹å›¾åƒ
            ep,  # HDF5æ–‡ä»¶å¯¹è±¡
            [  # ç›¸æœºåˆ—è¡¨
                "cam_high",  # é«˜ä½ç›¸æœº
                # "cam_low",  # ä½ä½ç›¸æœºï¼ˆå·²æ³¨é‡Šï¼‰
                "cam_left_wrist",  # å·¦è…•ç›¸æœº
                "cam_right_wrist",  # å³è…•ç›¸æœº
            ],
            verbose=verbose,  # ä¼ é€’verboseå‚æ•°
        )

        # å¤„ç†ä½ç½®æ•°æ®ï¼ˆlocalization/poseï¼‰- å¯é€‰åŠŸèƒ½
        if is_new_format and "/localization/pose" in ep:  # å¦‚æœå­˜åœ¨ä½ç½®æ•°æ®
            pose_left = ep["/localization/pose/puppetLeft"][:]  # è¯»å–å·¦è‡‚ä½ç½®æ•°æ®
            pose_right = ep["/localization/pose/puppetRight"][:]  # è¯»å–å³è‡‚ä½ç½®æ•°æ®
            if verbose:
                print(f"ä½ç½®æ•°æ® - å·¦è‡‚å½¢çŠ¶: {pose_left.shape}, å³è‡‚å½¢çŠ¶: {pose_right.shape}")  # æ‰“å°ä½ç½®æ•°æ®å½¢çŠ¶
            # æ³¨æ„ï¼šä½ç½®æ•°æ®ç›®å‰åªæ˜¯æ‰“å°ï¼Œå¦‚æœéœ€è¦å¯ä»¥æ·»åŠ åˆ°è¿”å›çš„å…ƒç»„ä¸­

    return imgs_per_cam, state, action, velocity, effort  # è¿”å›å›¾åƒå­—å…¸ã€çŠ¶æ€ã€åŠ¨ä½œã€é€Ÿåº¦ã€åŠ›çŸ©


def populate_dataset(  # å®šä¹‰å¡«å……æ•°æ®é›†çš„å‡½æ•°
    dataset: LeRobotDataset,  # LeRobotæ•°æ®é›†å¯¹è±¡
    hdf5_files: list[Path],  # HDF5æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    task: str,  # ä»»åŠ¡åç§°
    episodes: list[int] | None = None,  # è¦å¤„ç†çš„å‰§é›†ç´¢å¼•åˆ—è¡¨ï¼Œå¯é€‰
    quantiles: dict | None = None,  # åˆ†ä½æ•°å­—å…¸ï¼Œç”¨äºæ•°æ®å½’ä¸€åŒ–
    verbose: bool = False,  # æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
) -> LeRobotDataset:  # è¿”å›å¡«å……åçš„æ•°æ®é›†
    if episodes is None:  # å¦‚æœæ²¡æœ‰æŒ‡å®šå‰§é›†
        episodes = range(len(hdf5_files))  # å¤„ç†æ‰€æœ‰å‰§é›†

    if verbose:
        print(f"ğŸ¬ å¼€å§‹å¤„ç† {len(episodes)} ä¸ªå‰§é›†")
    
    for ep_idx in tqdm.tqdm(episodes):  # éå†æ‰€æœ‰å‰§é›†ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡
        ep_path = hdf5_files[ep_idx]  # è·å–å½“å‰å‰§é›†æ–‡ä»¶è·¯å¾„
        if verbose:
            print(f"\nğŸ“ å¤„ç†å‰§é›† {ep_idx}: {ep_path.name}")

        imgs_per_cam, state, action, velocity, effort = load_raw_episode_data(ep_path, quantiles=quantiles, verbose=verbose)  # åŠ è½½å‰§é›†æ•°æ®
        num_frames = state.shape[0]  # è·å–å¸§æ•°
        
        if verbose:
            print(f"ğŸ“Š å‰§é›†æ•°æ®ç»Ÿè®¡:")
            print(f"  ğŸ–¼ï¸ å›¾åƒæ•°æ®: {len(imgs_per_cam)} ä¸ªç›¸æœº")
            for cam, imgs in imgs_per_cam.items():
                print(f"    {cam}: {imgs.shape} ({imgs.size * imgs.dtype.itemsize / 1024 / 1024:.2f} MB)")
            print(f"  ğŸ¤– çŠ¶æ€æ•°æ®: {state.shape}")
            print(f"  ğŸ¯ åŠ¨ä½œæ•°æ®: {action.shape}")
            if velocity is not None:
                print(f"  âš¡ é€Ÿåº¦æ•°æ®: {velocity.shape}")
            if effort is not None:
                print(f"  ğŸ’ª åŠ›çŸ©æ•°æ®: {effort.shape}")

        frames_with_images = 0  # ç»Ÿè®¡æœ‰å›¾åƒçš„å¸§æ•°
        frames_without_images = 0  # ç»Ÿè®¡æ²¡æœ‰å›¾åƒçš„å¸§æ•°
        
        for i in range(num_frames):  # éå†æ‰€æœ‰å¸§
            frame = {  # åˆ›å»ºå¸§æ•°æ®å­—å…¸
                "observation.state": state[i],  # æ·»åŠ çŠ¶æ€è§‚å¯Ÿ
                "action": action[i],  # æ·»åŠ åŠ¨ä½œ
            }

            has_images = False  # æ ‡è®°æ˜¯å¦æœ‰å›¾åƒæ•°æ®
            for camera, img_array in imgs_per_cam.items():  # éå†æ‰€æœ‰ç›¸æœº
                if i < len(img_array):  # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                    frame[f"observation.images.{camera}"] = img_array[i]  # æ·»åŠ ç›¸æœºå›¾åƒè§‚å¯Ÿ
                    has_images = True  # æ ‡è®°æœ‰å›¾åƒ
                else:
                    if verbose:
                        print(f"  âš ï¸ è­¦å‘Š: å¸§ {i} è¶…å‡º {camera} å›¾åƒèŒƒå›´ ({len(img_array)} å¼ å›¾åƒ)")
            
            if has_images:
                frames_with_images += 1
            else:
                frames_without_images += 1
                if verbose:
                    print(f"  âš ï¸ è­¦å‘Š: å¸§ {i} æ²¡æœ‰å›¾åƒæ•°æ®")

            if velocity is not None:  # å¦‚æœå­˜åœ¨é€Ÿåº¦æ•°æ®
                frame["observation.velocity"] = velocity[i]  # æ·»åŠ é€Ÿåº¦è§‚å¯Ÿ
            if effort is not None:  # å¦‚æœå­˜åœ¨åŠ›çŸ©æ•°æ®
                frame["observation.effort"] = effort[i]  # æ·»åŠ åŠ›çŸ©è§‚å¯Ÿ

            frame["task"] = task  # æ·»åŠ ä»»åŠ¡æ ‡ç­¾

            dataset.add_frame(frame)  # å°†å¸§æ·»åŠ åˆ°æ•°æ®é›†

        if verbose:
            print(f"ğŸ“ˆ å‰§é›† {ep_idx} å®Œæˆ:")
            print(f"  âœ… æœ‰å›¾åƒçš„å¸§: {frames_with_images}")
            print(f"  âŒ æ— å›¾åƒçš„å¸§: {frames_without_images}")
            print(f"  ğŸ“Š æ€»å¸§æ•°: {num_frames}")
        
        dataset.save_episode()  # ä¿å­˜å‰§é›†
        if verbose:
            print(f"  ğŸ’¾ å‰§é›†å·²ä¿å­˜")

    if verbose:
        print(f"\nğŸ‰ æ‰€æœ‰å‰§é›†å¤„ç†å®Œæˆ!")
    return dataset  # è¿”å›å¡«å……åçš„æ•°æ®é›†


def port_aloha(  # å®šä¹‰è½¬æ¢Alohaæ•°æ®çš„ä¸»å‡½æ•°
    raw_dir: Path,  # åŸå§‹æ•°æ®ç›®å½•è·¯å¾„
    repo_id: str,  # ä»“åº“ID
    raw_repo_id: str | None = None,  # åŸå§‹ä»“åº“IDï¼Œå¯é€‰
    task: str = "DEBUG",  # ä»»åŠ¡åç§°ï¼Œé»˜è®¤ä¸º"DEBUG"
    *,  # å¼ºåˆ¶å…³é”®å­—å‚æ•°åˆ†éš”ç¬¦
    episodes: list[int] | None = None,  # è¦å¤„ç†çš„å‰§é›†åˆ—è¡¨ï¼Œå¯é€‰
    push_to_hub: bool = False,  # æ˜¯å¦æ¨é€åˆ°Hubï¼Œé»˜è®¤ä¸ºFalse
    is_mobile: bool = False,  # æ˜¯å¦ä¸ºç§»åŠ¨æœºå™¨äººï¼Œé»˜è®¤ä¸ºFalse
    mode: Literal["video", "image"] = "image",  # æ•°æ®æ¨¡å¼ï¼Œé»˜è®¤ä¸ºå›¾åƒ
    dataset_config: DatasetConfig = DEFAULT_DATASET_CONFIG,  # æ•°æ®é›†é…ç½®
):
    if (HF_LEROBOT_HOME / repo_id).exists():  # å¦‚æœæ•°æ®é›†ç›®å½•å·²å­˜åœ¨
        print("æ•°æ®é›†ç›®å½•å·²å­˜åœ¨",HF_LEROBOT_HOME / repo_id)
        shutil.rmtree(HF_LEROBOT_HOME / repo_id)  # åˆ é™¤ç°æœ‰ç›®å½•

    # if not raw_dir.exists():  # æ³¨é‡Šæ‰çš„åŸå§‹ç›®å½•æ£€æŸ¥
    #     if raw_repo_id is None:  # æ³¨é‡Šæ‰çš„åŸå§‹ä»“åº“IDæ£€æŸ¥
    #         raise ValueError("raw_repo_id must be provided if raw_dir does not exist")  # æ³¨é‡Šæ‰çš„é”™è¯¯æŠ›å‡º
    #     download_raw(raw_dir, repo_id=raw_repo_id)  # æ³¨é‡Šæ‰çš„åŸå§‹æ•°æ®ä¸‹è½½

    hdf5_files = [  # æŸ¥æ‰¾æ‰€æœ‰HDF5æ–‡ä»¶
        Path(dirpath) / filename  # æ„å»ºæ–‡ä»¶è·¯å¾„
        for dirpath, _, filenames in os.walk(raw_dir, followlinks=True)  # éå†ç›®å½•æ ‘
        for filename in filenames  # éå†æ–‡ä»¶å
        if filename.endswith(".hdf5")  # ç­›é€‰HDF5æ–‡ä»¶
    ]
    
    if dataset_config.verbose:
        print(f"ğŸ” æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶:")
        for i, hdf5_file in enumerate(hdf5_files):
            file_size = hdf5_file.stat().st_size / 1024 / 1024  # æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            print(f"  {i}: {hdf5_file.name} ({file_size:.2f} MB)")

        # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„ç»“æ„
        if hdf5_files:
            print(f"\nğŸ”¬ åˆ†æç¬¬ä¸€ä¸ªæ–‡ä»¶: {hdf5_files[0].name}")
            try:
                with h5py.File(hdf5_files[0], "r") as f:
                    print("æ–‡ä»¶ç»“æ„:")
                    def print_structure(name, obj, level=0):
                        indent = "  " * level
                        if isinstance(obj, h5py.Dataset):
                            size_mb = obj.size * obj.dtype.itemsize / 1024 / 1024
                            print(f"{indent}ğŸ“„ {name} ({obj.dtype}, {obj.shape}, {size_mb:.2f} MB)")
                        else:
                            print(f"{indent}ğŸ“ {name}/")
                            if level < 2:  # åªæ˜¾ç¤ºå‰ä¸¤å±‚
                                for key in obj.keys():
                                    print_structure(key, obj[key], level + 1)
                    
                    f.visititems(print_structure)
            except Exception as e:
                print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {e}")

    dataset = create_empty_dataset(  # åˆ›å»ºç©ºæ•°æ®é›†
        repo_id,  # ä»“åº“ID
        robot_type="mobile_aloha" if is_mobile else "aloha",  # æ ¹æ®æ˜¯å¦ä¸ºç§»åŠ¨æœºå™¨äººé€‰æ‹©æœºå™¨äººç±»å‹
        mode=mode,  # æ•°æ®æ¨¡å¼
        has_effort=has_effort(hdf5_files),  # æ£€æŸ¥æ˜¯å¦åŒ…å«åŠ›çŸ©æ•°æ®
        has_velocity=has_velocity(hdf5_files),  # æ£€æŸ¥æ˜¯å¦åŒ…å«é€Ÿåº¦æ•°æ®
        dataset_config=dataset_config,  # æ•°æ®é›†é…ç½®
    )
    
    if dataset_config.verbose:
        print(f"\nğŸ—ï¸ åˆ›å»ºæ•°æ®é›†: {repo_id}")
        print(f"  ğŸ¤– æœºå™¨äººç±»å‹: {'mobile_aloha' if is_mobile else 'aloha'}")
        print(f"  ğŸ“Š æ•°æ®æ¨¡å¼: {mode}")
        print(f"  âš¡ åŒ…å«é€Ÿåº¦: {has_velocity(hdf5_files)}")
        print(f"  ğŸ’ª åŒ…å«åŠ›çŸ©: {has_effort(hdf5_files)}")
    
    # è®¡ç®—åˆ†ä½æ•°
    quantiles = calculate_quantiles(hdf5_files, verbose=dataset_config.verbose)
    
    task='Put the fork in the box.'  # è®¾ç½®ä»»åŠ¡åç§°ä¸º"Clean the table."
    dataset = populate_dataset(  # å¡«å……æ•°æ®é›†
        dataset,  # æ•°æ®é›†å¯¹è±¡
        hdf5_files,  # HDF5æ–‡ä»¶åˆ—è¡¨
        task=task,  # ä»»åŠ¡åç§°
        episodes=episodes,  # å‰§é›†åˆ—è¡¨
        quantiles=quantiles,  # ä¼ é€’è®¡ç®—çš„åˆ†ä½æ•°
        verbose=dataset_config.verbose,  # ä¼ é€’verboseå‚æ•°
    )

    if push_to_hub:  # å¦‚æœéœ€è¦æ¨é€åˆ°Hub
        dataset.push_to_hub()  # æ¨é€æ•°æ®é›†åˆ°Hub


if __name__ == "__main__":  # å¦‚æœä½œä¸ºä¸»ç¨‹åºè¿è¡Œ
    tyro.cli(port_aloha)  # ä½¿ç”¨tyroå‘½ä»¤è¡Œæ¥å£è°ƒç”¨port_alohaå‡½æ•°
